{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df5620d3",
   "metadata": {},
   "source": [
    "## HMMlearn ì„ ì´ìš©í•œ HMM í•™ìŠµê³¼ BKT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4b7263",
   "metadata": {},
   "source": [
    "### 1) ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "\n",
    "- `hmmlearn` ì„¤ì¹˜í•˜ê¸° : `pip install hmmlearn`\n",
    "-  hmmlearn 0.2.8 \n",
    "-  https://github.com/hmmlearn/hmmlearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88cd93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b372cc",
   "metadata": {},
   "source": [
    "### 2) CategorialHMM í•¨ìˆ˜\n",
    "\n",
    "- ê´€ì°° ë³€ìˆ˜ ë²”ì£¼í˜•(categorical) ë³€ìˆ˜ì¸ ê²½ìš° `CategoricalHMM()` í•¨ìˆ˜ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192290e",
   "metadata": {},
   "source": [
    "#### A. Parameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1b8ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ê´€ì°°ë³€ìˆ˜ì™€ ì ì¬ë³€ìˆ˜ê°€ binary variableì¼ ë•Œ parameter setting\n",
    "#initial probability\n",
    "startprob=np.array([0.7, 0.3])\n",
    "\n",
    "#transition matrix\n",
    "transmat=np.array([[0.6, 0.4],\n",
    "                  [0, 1]])\n",
    "#emission matrix\n",
    "emissionprob=np.array([[0.95, 0.05],\n",
    "                  [0.1, 0.9]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a3f155",
   "metadata": {},
   "source": [
    "#### B. Model setting\n",
    "\n",
    "-  `CategoricalHMM()` í•¨ìˆ˜ì˜ ëª¨ë¸ ì„¤ì •ê³¼ ê´€ë ¨í•œ ì¸ìˆ˜\n",
    "    - `params=''`, `init_params=''`  ì´ë©´ í•™ìŠµí•˜ì§€ ì•Šê³  ê¸°ì¡´ì— ì„¸íŒ…í•œ ëª¨ë“  parameterë¥¼ ê·¸ëŒ€ë¡œ fixí•œ ì±„ë¡œ í•™ìŠµí•¨\n",
    "    - `params='ste'` ì™€ ê°™ì´ ì„¤ì •í•˜ë©´ ste (t=transition, e=emission, s=start) ì¤‘ ë¹ ì§„ parameterëŠ” fixë˜ê³  ë‚˜ë¨¸ì§€ë§Œ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµë¨ \n",
    "    - `n_components` : number of hidden states for latent variable (ì ì¬ë³€ìˆ˜ì˜ ë²”ì£¼ ê°œìˆ˜)\n",
    "    \n",
    "    \n",
    "-  ëª¨ë¸ ë³€ìˆ˜ ì§€ì • í›„ parameter ë“± property \n",
    "    - `n_features` : number of states for output variable (ê´€ì°°ë³€ìˆ˜ì˜ ë²”ì£¼ ê°œìˆ˜)\n",
    "    - `startprob_` : start probability\n",
    "    - `transmat_` : transition probability matrix\n",
    "    - `emissionprob_` : emission probability matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd0ed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model setting\n",
    "model = hmm.CategoricalHMM(n_components=2, params='', init_params='')  \n",
    "model.n_features=2\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.emissionprob_ = emissionprob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d03404",
   "metadata": {},
   "source": [
    "#### C. Data generation and Model fitting\n",
    "- model settingì— ë”°ë¼ data generation í›„ í•™ìŠµ(fitting)\n",
    "- `sample()` methodë¥¼ ì‚¬ìš©í•˜ë©´ modelì˜ settingì— ë”°ë¼ ë°ì´í„°ê°€ ìƒì„±ë¨ \n",
    "- `fit()` methodë¥¼ setting í•œ modelì— ì ìš©í•˜ë©´ í•™ìŠµì´ ì´ë£¨ì–´ì§€ë©° ì´ë•Œ `fit(data)`ì™€ ê°™ì´ ì‚¬ìš©í•˜ë©° dataëŠ” ê´€ì°°ë³€ìˆ˜ì˜ sequenceì¸ (n, 1) array\n",
    "- ìœ„ì˜ model settingì—ì„œ `params=''`, `init_params=''` ë¡œ ì„¤ì •í•˜ì˜€ìœ¼ë¯€ë¡œ parameterëŠ” ì‹¤ì œ í•™ìŠµë˜ì§€ ì•Šê³  ì£¼ì–´ì§„ ê°’ì„ ê·¸ëŒ€ë¡œ ê³ ì •í•˜ì—¬ ê·¸ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•œë‹¤. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc4ad0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalHMM(init_params='', n_components=2, params='',\n",
       "               random_state=RandomState(MT19937) at 0x1D2EF393840)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data generation and model fitting\n",
    "\n",
    "X, Z = model.sample(10) #generate a single sequence of a length based on HMM model\n",
    "#X : ê´€ì°°ë³€ìˆ˜ì˜ sequence\n",
    "#Z : ì ì¬ë³€ìˆ˜ì˜ true sequence\n",
    "\n",
    "model.fit(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a6526a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XëŠ” (10,1) array\n",
    "X     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47bcc1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ZëŠ” (1, 10) array\n",
    "Z    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35eb5b6",
   "metadata": {},
   "source": [
    "#### D. Prediction and Decoding\n",
    "- `predict()` methodëŠ” (n, 1) array í˜•íƒœì˜ ê´€ì°°ë³€ìˆ˜ sequence ë¥¼ ì£¼ë©´ ì´ë¡œë¶€í„° ê° hidden stateë¥¼ ì˜ˆì¸¡í•œë‹¤. ì´ë•Œ marginal probability $P(q_t=1|sequence)$ ë¥¼ ê³„ì‚°í•˜ì—¬ 0.5ê°€ ë„˜ìœ¼ë©´ 1ë¡œ íŒì •í•œë‹¤. \n",
    "- `predict_proba()` methodëŠ” `predict()`ë¥¼ ì ìš©í•˜ê¸° ìœ„í•´ ê³„ì‚°í•˜ëŠ” $P(q_t=1|sequence)$ ë¥¼ ì•Œë ¤ì¤€ë‹¤. \n",
    "- `decode()` methodëŠ” (n, 1) array í˜•íƒœì˜ ê´€ì°°ë³€ìˆ˜ sequence ë¥¼ ì£¼ë©´ joint probability($P(q_1, q_2, \\cdots, q_t|sequence)$) ê°€ ê°€ì¥ ë†’ì€ hidden stateë¥¼ ì•Œë ¤ì¤€ë‹¤. outputì€ tuple í˜•íƒœë¡œ ë‘ ê°œì˜ ë³€ìˆ˜ì— ì €ì¥í•˜ëŠ”ë° ì•ì˜ ê°’ì€ í™•ë¥ ì˜ logê°’, ë’¤ì˜ ê°’ì€ ì¶”ì •ëœ hidden state ì´ë‹¤. \n",
    "- `score()` methodëŠ” (n, 1) array í˜•íƒœì˜ ê´€ì°°ë³€ìˆ˜ sequence ë¥¼ ì£¼ë©´ ì´ë¥¼ ê´€ì°°í•  joint probability($P(sequence)$)ì˜ log ê°’ì„ ê³„ì‚°í•´ì¤€ë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "251183e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#marginal probability ë¥¼ ì´ìš©í•œ hidden state ì¶”ì •\n",
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2ddcbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.296761798439953\n",
      "[0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#joint probabilityë¥¼ ì´ìš©í•œ hidden state ì¶”ì •\n",
    "logp, state=model.decode(X)\n",
    "print(logp)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab462d",
   "metadata": {},
   "source": [
    "- `fit()` ì„ ì´ìš©í•œ ëª¨ë¸í•™ìŠµì´ ëë‚œ ê²°ê³¼ë¡œë¶€í„° ê°ê° `startprob_`, `transmat_` ,`emissionprob_` ì˜ ê°’ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b0606f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6, 0.4],\n",
       "       [0. , 1. ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ìƒˆë¡œ í•™ìŠµë˜ì§€ ì•Šê³  ì²˜ìŒ fixëœ transition matrix ê°€ ë§ëŠ”ì§€ í™•ì¸í•œë‹¤. \n",
    "model.transmat_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae520ef",
   "metadata": {},
   "source": [
    "### 3) ì˜ˆì‹œ ë¬¸ì œ í’€ê¸°\n",
    "\n",
    "- ì˜ˆì‹œì—ì„œ  ê´€ì°°ë³€ìˆ˜ sequenceê°€ $(ğ‘¦_1,â‹¯,ğ‘¦_4)=(0, 0, 1, 1)$ ë¡œ ì£¼ì–´ì¡Œì„ ë•Œ, 1), 2), 3), 4)ë¥¼ êµ¬í•´ë³´ì. \n",
    "\n",
    "1)  $ğ‘ƒ(ğ‘¦_1=0,ğ‘¦_2=0,ğ‘¦_3=1,ğ‘¦_4=1)$, ì¦‰, ìœ„ì˜ ê´€ì°° ê²°ê³¼ë¥¼ ì–»ì„ í™•ë¥ (joint probability)ì„ êµ¬í•´ë³´ì. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd7e3b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8889991483194628 0.15122308499999998\n"
     ]
    }
   ],
   "source": [
    "#score() ë¥¼ ì‚¬ìš©\n",
    "y=np.array([[0],[0],[1],[1]])\n",
    "logp=model.score(y) #log likelihood of X -> correct \n",
    "print(logp, np.exp(logp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4e87fc",
   "metadata": {},
   "source": [
    "2) $ğ‘ƒ(ğ‘_1,ğ‘_2,ğ‘_3,ğ‘_4 |ğ‘¦_1=0,ğ‘¦_2=0,ğ‘¦_3=1,ğ‘¦_4=1)$ ê°€ ê°€ì¥ ë†’ì€ $ğ‘_1,ğ‘_2,ğ‘_3,ğ‘_4$ ì˜ ê°’ì€ ì–´ë–¤ ê²½ìš°ì¸ê°€?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99008a6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.097098919669632 0.12281219999999998\n",
      "[0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "logp, state=model.decode(y) #viterbi algoritm (ë¶„ì ê³„ì‚°)\n",
    "print(logp,np.exp(logp))\n",
    "print(state)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c85a8729",
   "metadata": {},
   "source": [
    "3) $ğ‘ƒ(ğ‘_5=1 |ğ‘¦_1=0,ğ‘¦_2=0,ğ‘¦_3=1,ğ‘¦_4=1)$ ë¥¼ ì˜ˆì¸¡í•˜ì—¬ë¼.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80c74d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict í•¨ìˆ˜ëŠ” marginal probability(P(q_i=1)) ì„ ê³„ì‚°í•´ì„œ ê° sequenceì˜ stateë¥¼ ì˜ˆì¸¡(ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ state)  \n",
    "\n",
    "model.predict(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "909a4bee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98393102, 0.01606898],\n",
       "       [0.84145278, 0.15854722],\n",
       "       [0.02932677, 0.97067323],\n",
       "       [0.00225591, 0.99774409]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(y) #predict marginal probability  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cffc519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.998646456657064"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P(q_4=1|[0, 0, 1, 1])ê³¼ P(q_4=0|[0, 0, 1, 1])ê³¼ transition probability ì´ìš©í•˜ì—¬ ê³„ì‚°\n",
    "model.predict_proba(y)[3][0]*0.4+model.predict_proba(y)[3][1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2594bc45",
   "metadata": {},
   "source": [
    "4) $ğ‘ƒ(ğ‘¦_5=1|ğ‘¦_1=0,ğ‘¦_2=0,ğ‘¦_3=1,ğ‘¦_4=1)$ ë¥¼ ì˜ˆì¸¡í•˜ì—¬ë¼. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "23ae0566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8988494881585044"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ìœ„ì˜ ê²°ê³¼ì™€ emission probabilityë¥¼ ì´ìš©í•˜ì—¬ ê³„ì‚°\n",
    "p=model.predict_proba(y)[3][0]*0.4+model.predict_proba(y)[3][1]\n",
    "0.9*p+0.05*(1-p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe58a6c",
   "metadata": {},
   "source": [
    "### 4) Dataë¡œ ë¶€í„° í•™ìŠµí•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8feaefe",
   "metadata": {},
   "source": [
    "- `CategoricalHMM()` í•¨ìˆ˜ë¥¼ ì´ìš©í•´ ì‹¤ì œ sequence ë°ì´í„°ë¥¼ ì£¼ê³  parameterë“¤ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆë‹¤. \n",
    "- `hmm.CategoricalMHH(n_componetns=2).fit(X, lengths)`: ì—¬ëŸ¬ sampleì˜ sequence(multiple sequence)ë¥¼ í•©ì³ì„œ Xë¥¼ (n, 1) arrayë¡œ ë§Œë“¤ì–´ í•™ìŠµì‹œí‚¤ë©´ì„œ ë™ì‹œì— ê° sequenceì˜ ê¸¸ì´ë¥¼ legnths ì¸ìˆ˜ë¡œ ì•Œë ¤ì¤€ë‹¤. \n",
    "- ì´ ë°©ë²•ì€ ê¸¸ì´ê°€ ë‹¤ë¥¸ sequence ë“¤ì„ í•©ì³ì„œ ì‚¬ìš©ê°€ëŠ¥í•˜ê²Œ í•´ì¤€ë‹¤. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c89ee",
   "metadata": {},
   "source": [
    "#### A. ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0fbb06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì£¼ì–´ì§„ ë°ì´í„° (10ëª…ì˜ ë°ì´í„°, 4 step)\n",
    "l_seq=4\n",
    "n_sample=10\n",
    "\n",
    "#Xseq ì€ (n_sample*l_seq, 1) ì˜ ëª¨ì–‘ì„\n",
    "Xseq=np.array([[0],[0],[1],[1],\n",
    "             [0],[0],[1],[1],\n",
    "             [0],[0],[0],[1],\n",
    "             [0],[0],[0],[1],\n",
    "             [0],[0],[1],[1],\n",
    "             [0],[1],[1],[1],\n",
    "             [0],[1],[1],[1],\n",
    "             [1],[0],[1],[1],\n",
    "             [1],[1],[1],[1],\n",
    "             [1],[1],[1],[1]]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "63d9635a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalHMM(n_components=2,\n",
       "               random_state=RandomState(MT19937) at 0x1D2EF393840)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fiting ( one time -local optimization)\n",
    "#random initial pointì—ì„œ ì§„í–‰ë¨\n",
    "model1 = hmm.CategoricalHMM(n_components=2)  \n",
    "model1.n_features=2\n",
    "model1.fit(Xseq,[l_seq]*n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b2873bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvergenceMonitor(\n",
       "    history=[-35.55174456069207, -25.284182779027006, -23.66822273092971, -21.73669696731069, -20.30780388137565, -19.68895682114933, -19.476790053308417, -19.40274805940719, -19.372709317296042, -19.354516310641003],\n",
       "    iter=10,\n",
       "    n_iter=10,\n",
       "    tol=0.01,\n",
       "    verbose=False,\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convergence monitoring\n",
    "model1.monitor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "707be895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72358073, 0.27641927])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initial probability learned\n",
    "model1.startprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d5efbfa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.82675332e-01, 5.17324668e-01],\n",
       "       [4.73177321e-06, 9.99995268e-01]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transition probability learned\n",
    "model1.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "675abac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96612727, 0.03387273],\n",
       "       [0.05880891, 0.94119109]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#emission probability learned\n",
    "model1.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "df05676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#í•™ìŠµì„ ë°˜ë³µí•´ì„œ ë°°ìŠ¤íŠ¸ ëª¨ë¸ì„ ì°¾ê¸°\n",
    "# repeating and finding the best results (random initialization)\n",
    "\n",
    "best_score = best_model = None\n",
    "n_fits = 1000\n",
    "for i in range(n_fits):\n",
    "    modeleach = hmm.CategoricalHMM(n_components=2)\n",
    "    modeleach.fit(Xseq,[l_seq]*n_sample)\n",
    "    score = modeleach.score(Xseq)\n",
    "    #print(f'Model #{i+1}\\tScore: {score}')\n",
    "    if best_score is None or score > best_score:\n",
    "        best_model = modeleach\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "03555910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-23.943035084614134"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fc9d52f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.318, 0.682])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.startprob_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b91a9109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.   , 0.   ],\n",
       "       [0.109, 0.891]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.transmat_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1a2398cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.151, 0.849],\n",
       "       [0.536, 0.464]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.emissionprob_.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b819c8b",
   "metadata": {},
   "source": [
    "#### B. ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  í•™ìŠµí•´ ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ceed3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-sequence ê°€ìƒ ë°ì´í„°ë¥¼ ìƒì„±í•˜ë ¤ë©´ ë‹¤ìŒê³¼ ê°™ì´ í•œë‹¤.\n",
    "#HMM setting for data generation of multiple sequences \n",
    "\n",
    "#HMM parameter setting\n",
    "startprob=np.array([0.7, 0.3])\n",
    "transmat=np.array([[0.6, 0.4],\n",
    "                  [0, 1]])\n",
    "emissionprob=np.array([[0.95, 0.05],\n",
    "                  [0.1, 0.9]])\n",
    "\n",
    "#model setting \n",
    "model = hmm.CategoricalHMM(n_components=2, params='', init_params='')  \n",
    "model.n_features=2\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.emissionprob_ = emissionprob\n",
    "\n",
    "#data generation\n",
    "n_sample=10000   #n_sample : sample size (sequenceì˜ ê°œìˆ˜)\n",
    "l_seq=10       #l_seq : sequenceì˜ time step  ê°œìˆ˜\n",
    "Xseq=np.zeros(shape=(n_sample*l_seq, 1), dtype=int) #ìµœì¢… multi sequence dataë¥¼ ì €ì¥í•  ë³€ìˆ˜\n",
    "Zseq=np.zeros(shape=(n_sample*l_seq, ), dtype=int)\n",
    "for i in range(n_sample):\n",
    "    X, Z = model.sample(l_seq) \n",
    "    Xseq[(i*l_seq):(i+1)*l_seq]=X\n",
    "    Zseq[(i*l_seq):(i+1)*l_seq]=Z\n",
    "    #if i <10 : \n",
    "    #    print(X)\n",
    "    #    print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "d21c3c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CategoricalHMM(n_components=2,\n",
       "               random_state=RandomState(MT19937) at 0x1D2EF393840)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model fiting ( one time -local optimization)\n",
    "#random initial pointì—ì„œ ì§„í–‰ë¨\n",
    "model2 = hmm.CategoricalHMM(n_components=2)  \n",
    "model2.n_features=2\n",
    "model2.fit(Xseq,[l_seq]*n_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "96f7db92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvergenceMonitor(\n",
       "    history=[-78052.02352132813, -56026.50242196378, -55957.89122569403, -55919.073405796604, -55886.73363097737, -55855.27577544248, -55823.70994643497, -55792.22535953317, -55761.25784469623, -55731.22014722861],\n",
       "    iter=10,\n",
       "    n_iter=10,\n",
       "    tol=0.01,\n",
       "    verbose=False,\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convergence monitoring\n",
    "model2.monitor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "53a4d4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13268155, 0.86731845])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initial probability learned\n",
    "model2.startprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ea9648bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1866936 , 0.8133064 ],\n",
       "       [0.95388712, 0.04611288]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#transition probability learned\n",
    "model2.transmat_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3a57ddf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19961316, 0.80038684],\n",
       "       [0.30182398, 0.69817602]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#emission probability learned\n",
    "model2.emissionprob_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "50736048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-56332.88675187469"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ìµœì¢… loss function ê°’\n",
    "model2.score(Xseq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d49eb678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\tScore: -56071.50405763127\n",
      "Model #2\tScore: -55541.012684816604\n",
      "Model #3\tScore: -55527.80456797091\n",
      "Model #4\tScore: -57645.09402203622\n",
      "Model #5\tScore: -59133.80497400741\n",
      "Model #6\tScore: -56443.0903945478\n",
      "Model #7\tScore: -56706.44085875095\n",
      "Model #8\tScore: -56309.19012335569\n",
      "Model #9\tScore: -56632.58935271051\n",
      "Model #10\tScore: -54649.85245271422\n",
      "Model #11\tScore: -55226.70251403452\n",
      "Model #12\tScore: -55706.138587900736\n",
      "Model #13\tScore: -56301.188901545036\n",
      "Model #14\tScore: -60367.33981529027\n",
      "Model #15\tScore: -55218.0458011816\n",
      "Model #16\tScore: -57845.13648940478\n",
      "Model #17\tScore: -59234.08409606974\n",
      "Model #18\tScore: -57899.92691813912\n",
      "Model #19\tScore: -54826.18119449448\n",
      "Model #20\tScore: -56338.89960001078\n",
      "Model #21\tScore: -56729.90229157405\n",
      "Model #22\tScore: -56602.97038791846\n",
      "Model #23\tScore: -56719.57407347846\n",
      "Model #24\tScore: -58288.43967739815\n",
      "Model #25\tScore: -59357.92387931747\n",
      "Model #26\tScore: -55743.09537055125\n",
      "Model #27\tScore: -55781.898129080684\n",
      "Model #28\tScore: -56526.329802344386\n",
      "Model #29\tScore: -62478.03784090197\n",
      "Model #30\tScore: -61049.05041986571\n",
      "Model #31\tScore: -62231.843796948895\n",
      "Model #32\tScore: -63996.089634939904\n",
      "Model #33\tScore: -54454.17733847744\n",
      "Model #34\tScore: -56530.471932284374\n",
      "Model #35\tScore: -61533.009207357834\n",
      "Model #36\tScore: -58156.89988483044\n",
      "Model #37\tScore: -56835.635760734745\n",
      "Model #38\tScore: -60481.44623449318\n",
      "Model #39\tScore: -57888.69306631733\n",
      "Model #40\tScore: -57381.27452914869\n",
      "Model #41\tScore: -56890.85623760346\n",
      "Model #42\tScore: -54296.22754302654\n",
      "Model #43\tScore: -56292.14272497245\n",
      "Model #44\tScore: -56205.34064302906\n",
      "Model #45\tScore: -56494.18343272022\n",
      "Model #46\tScore: -56013.64089403643\n",
      "Model #47\tScore: -58157.63740997735\n",
      "Model #48\tScore: -55064.28329990067\n",
      "Model #49\tScore: -56301.91601350811\n",
      "Model #50\tScore: -55248.48975048469\n",
      "Model #51\tScore: -56273.524548369955\n",
      "Model #52\tScore: -54062.037843240265\n",
      "Model #53\tScore: -56145.133401741274\n",
      "Model #54\tScore: -54639.40406789881\n",
      "Model #55\tScore: -59413.14770273753\n",
      "Model #56\tScore: -56489.0924321657\n",
      "Model #57\tScore: -56599.59310600975\n",
      "Model #58\tScore: -56385.99920883229\n",
      "Model #59\tScore: -55137.37661990634\n",
      "Model #60\tScore: -56271.72459138263\n",
      "Model #61\tScore: -57097.80125378943\n",
      "Model #62\tScore: -56501.98339526592\n",
      "Model #63\tScore: -55778.26119504746\n",
      "Model #64\tScore: -57024.2008161465\n",
      "Model #65\tScore: -61368.26240189857\n",
      "Model #66\tScore: -56579.18432929054\n",
      "Model #67\tScore: -56524.553003271045\n",
      "Model #68\tScore: -62024.61145890586\n",
      "Model #69\tScore: -56093.12131232836\n",
      "Model #70\tScore: -59307.07024336456\n",
      "Model #71\tScore: -56113.546362169436\n",
      "Model #72\tScore: -55032.60616300848\n",
      "Model #73\tScore: -56331.07527171947\n",
      "Model #74\tScore: -61302.88237099948\n",
      "Model #75\tScore: -63602.17443405815\n",
      "Model #76\tScore: -57717.24139588748\n",
      "Model #77\tScore: -53919.882726082746\n",
      "Model #78\tScore: -60492.26852679907\n",
      "Model #79\tScore: -61046.4519104242\n",
      "Model #80\tScore: -56649.23462610156\n",
      "Model #81\tScore: -54465.890163021744\n",
      "Model #82\tScore: -56732.75244303447\n",
      "Model #83\tScore: -60580.33291993809\n",
      "Model #84\tScore: -56377.75123045554\n",
      "Model #85\tScore: -55344.46811806321\n",
      "Model #86\tScore: -56053.183743486035\n",
      "Model #87\tScore: -55798.14863978652\n",
      "Model #88\tScore: -53704.25144731043\n",
      "Model #89\tScore: -54712.92377515262\n",
      "Model #90\tScore: -56376.1793205402\n",
      "Model #91\tScore: -59779.06097447282\n",
      "Model #92\tScore: -61348.455522630866\n",
      "Model #93\tScore: -54572.88155874356\n",
      "Model #94\tScore: -56533.70218110155\n",
      "Model #95\tScore: -59480.07957287822\n",
      "Model #96\tScore: -56404.69320502848\n",
      "Model #97\tScore: -63374.88574757231\n",
      "Model #98\tScore: -53808.21641379625\n",
      "Model #99\tScore: -60463.254715086594\n",
      "Model #100\tScore: -64809.3086770865\n",
      "Model #101\tScore: -56439.019609525894\n",
      "Model #102\tScore: -56751.005896288676\n",
      "Model #103\tScore: -56669.792813132844\n",
      "Model #104\tScore: -54455.89386197176\n",
      "Model #105\tScore: -56476.415891388366\n",
      "Model #106\tScore: -56450.60613689994\n",
      "Model #107\tScore: -59274.29098934671\n",
      "Model #108\tScore: -56123.24128830493\n",
      "Model #109\tScore: -55693.3911899622\n",
      "Model #110\tScore: -56146.25186658869\n",
      "Model #111\tScore: -54315.347730963025\n",
      "Model #112\tScore: -56586.488938032744\n",
      "Model #113\tScore: -55223.01751567949\n",
      "Model #114\tScore: -55808.64111574347\n",
      "Model #115\tScore: -56449.69916169524\n",
      "Model #116\tScore: -57095.619489834025\n",
      "Model #117\tScore: -59297.00293909684\n",
      "Model #118\tScore: -56370.27216321091\n",
      "Model #119\tScore: -56296.72188906546\n",
      "Model #120\tScore: -54700.82145346195\n",
      "Model #121\tScore: -56421.57164342746\n",
      "Model #122\tScore: -54781.611120479196\n",
      "Model #123\tScore: -55943.76385162213\n",
      "Model #124\tScore: -53762.48765352119\n",
      "Model #125\tScore: -56785.93736661572\n",
      "Model #126\tScore: -56247.2109151647\n",
      "Model #127\tScore: -56562.823647972684\n",
      "Model #128\tScore: -56577.07913131212\n",
      "Model #129\tScore: -58082.26893590673\n",
      "Model #130\tScore: -60271.623471260464\n",
      "Model #131\tScore: -58531.899004782215\n",
      "Model #132\tScore: -54698.33983464325\n",
      "Model #133\tScore: -55960.51347105922\n",
      "Model #134\tScore: -56581.394486703124\n",
      "Model #135\tScore: -56042.837223678565\n",
      "Model #136\tScore: -55687.00400021611\n",
      "Model #137\tScore: -56441.12454412344\n",
      "Model #138\tScore: -54491.09336993861\n",
      "Model #139\tScore: -54654.113503315224\n",
      "Model #140\tScore: -56891.22954683016\n",
      "Model #141\tScore: -58634.16826150285\n",
      "Model #142\tScore: -55169.19093771228\n",
      "Model #143\tScore: -57239.58494675226\n",
      "Model #144\tScore: -58194.86749973863\n",
      "Model #145\tScore: -56102.5452238496\n",
      "Model #146\tScore: -60903.778476169995\n",
      "Model #147\tScore: -56206.43491578947\n",
      "Model #148\tScore: -60815.26231895159\n",
      "Model #149\tScore: -55952.20458339605\n",
      "Model #150\tScore: -53886.722627438605\n",
      "Model #151\tScore: -61529.07360941604\n",
      "Model #152\tScore: -56230.84342073233\n",
      "Model #153\tScore: -56348.06683696507\n",
      "Model #154\tScore: -55184.39237643384\n",
      "Model #155\tScore: -54685.19151316842\n",
      "Model #156\tScore: -64748.65708704975\n",
      "Model #157\tScore: -56221.38167703107\n",
      "Model #158\tScore: -55761.701839576766\n",
      "Model #159\tScore: -64612.72327576529\n",
      "Model #160\tScore: -56976.344322497935\n",
      "Model #161\tScore: -57003.14765511438\n",
      "Model #162\tScore: -56136.30200645837\n",
      "Model #163\tScore: -59969.21302249749\n",
      "Model #164\tScore: -62551.53510351707\n",
      "Model #165\tScore: -56433.951562033006\n",
      "Model #166\tScore: -54355.1239947355\n",
      "Model #167\tScore: -57917.42724409708\n",
      "Model #168\tScore: -54440.67553654548\n",
      "Model #169\tScore: -56332.231410470406\n",
      "Model #170\tScore: -56760.55404412768\n",
      "Model #171\tScore: -56294.365908764594\n",
      "Model #172\tScore: -56566.11694920374\n",
      "Model #173\tScore: -56366.0102795328\n",
      "Model #174\tScore: -55092.01935234612\n",
      "Model #175\tScore: -56267.20940217345\n",
      "Model #176\tScore: -56953.68140209188\n",
      "Model #177\tScore: -54441.372800951875\n",
      "Model #178\tScore: -56534.95607632568\n",
      "Model #179\tScore: -56543.429651089646\n",
      "Model #180\tScore: -56196.8950429142\n",
      "Model #181\tScore: -60755.451180485055\n",
      "Model #182\tScore: -56176.62777737209\n",
      "Model #183\tScore: -65308.0884641309\n",
      "Model #184\tScore: -59801.31720580532\n",
      "Model #185\tScore: -58498.748509734076\n",
      "Model #186\tScore: -56218.42895087958\n",
      "Model #187\tScore: -55367.99578135054\n",
      "Model #188\tScore: -61547.7921401988\n",
      "Model #189\tScore: -54872.92096035406\n",
      "Model #190\tScore: -56540.281307274294\n",
      "Model #191\tScore: -59145.080908696116\n",
      "Model #192\tScore: -56731.27173553818\n",
      "Model #193\tScore: -63083.58718577434\n",
      "Model #194\tScore: -54606.00010463442\n",
      "Model #195\tScore: -54868.5684150772\n",
      "Model #196\tScore: -60039.73213383374\n",
      "Model #197\tScore: -56475.52441787659\n",
      "Model #198\tScore: -54301.489023864466\n",
      "Model #199\tScore: -55365.336014227556\n",
      "Model #200\tScore: -56714.62114727624\n",
      "Model #201\tScore: -56146.29553887679\n",
      "Model #202\tScore: -56717.737644316134\n",
      "Model #203\tScore: -60847.23062127279\n",
      "Model #204\tScore: -61099.09913813015\n",
      "Model #205\tScore: -56743.171569049555\n",
      "Model #206\tScore: -56437.52012868963\n",
      "Model #207\tScore: -56396.282696544375\n",
      "Model #208\tScore: -56365.82118664618\n",
      "Model #209\tScore: -56202.95171741352\n",
      "Model #210\tScore: -61692.01776319588\n",
      "Model #211\tScore: -56448.047208839525\n",
      "Model #212\tScore: -54771.908217896125\n",
      "Model #213\tScore: -60927.89364773928\n",
      "Model #214\tScore: -54992.6066639612\n",
      "Model #215\tScore: -55524.463996987695\n",
      "Model #216\tScore: -60686.70893691795\n",
      "Model #217\tScore: -58440.16207380486\n",
      "Model #218\tScore: -54665.42865746496\n",
      "Model #219\tScore: -56413.99057357014\n",
      "Model #220\tScore: -59965.56980080844\n",
      "Model #221\tScore: -53871.90729418761\n",
      "Model #222\tScore: -62826.77695293872\n",
      "Model #223\tScore: -55196.653029433386\n",
      "Model #224\tScore: -54557.69486688531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #225\tScore: -55088.52387469561\n",
      "Model #226\tScore: -57125.12395957391\n",
      "Model #227\tScore: -56514.58649106818\n",
      "Model #228\tScore: -56114.761732621286\n",
      "Model #229\tScore: -63073.46139225535\n",
      "Model #230\tScore: -54106.02754859992\n",
      "Model #231\tScore: -58797.2198241777\n",
      "Model #232\tScore: -68963.53894046898\n",
      "Model #233\tScore: -55202.23501632577\n",
      "Model #234\tScore: -60084.00721855096\n",
      "Model #235\tScore: -58322.835595227116\n",
      "Model #236\tScore: -55660.73512783146\n",
      "Model #237\tScore: -54359.48905308987\n",
      "Model #238\tScore: -61682.81835119832\n",
      "Model #239\tScore: -58392.40097353658\n",
      "Model #240\tScore: -56074.43532223011\n",
      "Model #241\tScore: -57927.82350591309\n",
      "Model #242\tScore: -55079.139197119446\n",
      "Model #243\tScore: -64832.826887893534\n",
      "Model #244\tScore: -59586.706486374205\n",
      "Model #245\tScore: -56568.348237319966\n",
      "Model #246\tScore: -56135.19462574999\n",
      "Model #247\tScore: -53688.11401685112\n",
      "Model #248\tScore: -57571.2827494252\n",
      "Model #249\tScore: -60179.0692960717\n",
      "Model #250\tScore: -59543.82870330093\n",
      "Model #251\tScore: -56466.775754083355\n",
      "Model #252\tScore: -55938.51900722468\n",
      "Model #253\tScore: -56134.718995000425\n",
      "Model #254\tScore: -56826.822244218965\n",
      "Model #255\tScore: -59522.75509762642\n",
      "Model #256\tScore: -56877.80613379253\n",
      "Model #257\tScore: -56919.98833755453\n",
      "Model #258\tScore: -53698.561847684425\n",
      "Model #259\tScore: -56530.94455294371\n",
      "Model #260\tScore: -54623.59416977494\n",
      "Model #261\tScore: -56760.28857810093\n",
      "Model #262\tScore: -55340.28014966612\n",
      "Model #263\tScore: -56112.91107372512\n",
      "Model #264\tScore: -56311.12294390307\n",
      "Model #265\tScore: -56247.46832105631\n",
      "Model #266\tScore: -64595.32170641708\n",
      "Model #267\tScore: -55795.224707498885\n",
      "Model #268\tScore: -56341.69240436807\n",
      "Model #269\tScore: -62055.3065160337\n",
      "Model #270\tScore: -63067.768194778655\n",
      "Model #271\tScore: -56660.03600407304\n",
      "Model #272\tScore: -57358.29671240305\n",
      "Model #273\tScore: -56775.28888837103\n",
      "Model #274\tScore: -54698.712464331315\n",
      "Model #275\tScore: -54666.17848585999\n",
      "Model #276\tScore: -59575.66743616397\n",
      "Model #277\tScore: -56187.71515691485\n",
      "Model #278\tScore: -56315.67840281188\n",
      "Model #279\tScore: -55125.41663411405\n",
      "Model #280\tScore: -56789.40064845685\n",
      "Model #281\tScore: -54551.25773316756\n",
      "Model #282\tScore: -56174.271143659695\n",
      "Model #283\tScore: -56113.931370277074\n",
      "Model #284\tScore: -56704.88521715868\n",
      "Model #285\tScore: -56162.05122081331\n",
      "Model #286\tScore: -60028.665465268095\n",
      "Model #287\tScore: -56125.769994790484\n",
      "Model #288\tScore: -56520.15041840366\n",
      "Model #289\tScore: -56642.56527257179\n",
      "Model #290\tScore: -55128.329575501804\n",
      "Model #291\tScore: -56526.44205884633\n",
      "Model #292\tScore: -54770.978589402264\n",
      "Model #293\tScore: -57021.181170715085\n",
      "Model #294\tScore: -53727.72780564823\n",
      "Model #295\tScore: -56337.32947793275\n",
      "Model #296\tScore: -62374.81893599655\n",
      "Model #297\tScore: -61049.06927725647\n",
      "Model #298\tScore: -57989.17295708501\n",
      "Model #299\tScore: -59184.172933533875\n",
      "Model #300\tScore: -56520.92922110278\n",
      "Model #301\tScore: -56316.96459142211\n",
      "Model #302\tScore: -57819.28471646051\n",
      "Model #303\tScore: -56625.58184589733\n",
      "Model #304\tScore: -62613.380678158435\n",
      "Model #305\tScore: -53941.28319249344\n",
      "Model #306\tScore: -56718.93309845028\n",
      "Model #307\tScore: -57177.26251949565\n",
      "Model #308\tScore: -54772.130788939736\n",
      "Model #309\tScore: -60593.51718041874\n",
      "Model #310\tScore: -64849.0541830339\n",
      "Model #311\tScore: -55882.409555299266\n",
      "Model #312\tScore: -56546.29244069384\n",
      "Model #313\tScore: -53685.79894358745\n",
      "Model #314\tScore: -60873.10360933322\n",
      "Model #315\tScore: -55862.85793651296\n",
      "Model #316\tScore: -58156.8949629131\n",
      "Model #317\tScore: -60506.106235958905\n",
      "Model #318\tScore: -56508.34134599661\n",
      "Model #319\tScore: -56521.27691574286\n",
      "Model #320\tScore: -56150.00613678383\n",
      "Model #321\tScore: -56105.549725188706\n",
      "Model #322\tScore: -54647.04366476142\n",
      "Model #323\tScore: -56475.81268524752\n",
      "Model #324\tScore: -60312.361906820035\n",
      "Model #325\tScore: -57384.22923155882\n",
      "Model #326\tScore: -59044.165288222495\n",
      "Model #327\tScore: -56344.82176970568\n",
      "Model #328\tScore: -55817.45208906156\n",
      "Model #329\tScore: -56144.184211598\n",
      "Model #330\tScore: -59753.62758225285\n",
      "Model #331\tScore: -56204.67497856113\n",
      "Model #332\tScore: -56803.78733805535\n",
      "Model #333\tScore: -56202.7450073688\n",
      "Model #334\tScore: -55761.852562912085\n",
      "Model #335\tScore: -59660.37016453289\n",
      "Model #336\tScore: -59300.4239070945\n",
      "Model #337\tScore: -56746.970312083475\n",
      "Model #338\tScore: -54182.05739600447\n",
      "Model #339\tScore: -61474.78033698728\n",
      "Model #340\tScore: -56406.02989710728\n",
      "Model #341\tScore: -56155.191520529006\n",
      "Model #342\tScore: -58374.80282833874\n",
      "Model #343\tScore: -58944.43305198051\n",
      "Model #344\tScore: -54852.93263365149\n",
      "Model #345\tScore: -56015.9104801732\n",
      "Model #346\tScore: -57506.927134593665\n",
      "Model #347\tScore: -56263.90304703004\n",
      "Model #348\tScore: -56860.46186583891\n",
      "Model #349\tScore: -64148.526341803205\n",
      "Model #350\tScore: -54542.65687590914\n",
      "Model #351\tScore: -54509.02605284093\n",
      "Model #352\tScore: -55799.38873927513\n",
      "Model #353\tScore: -57548.01125066625\n",
      "Model #354\tScore: -55955.344901179764\n",
      "Model #355\tScore: -56506.64800648113\n",
      "Model #356\tScore: -58245.099728551\n",
      "Model #357\tScore: -54832.773689078866\n",
      "Model #358\tScore: -62849.18532091792\n",
      "Model #359\tScore: -57119.5088472499\n",
      "Model #360\tScore: -54927.53127207619\n",
      "Model #361\tScore: -55981.125773200554\n",
      "Model #362\tScore: -54249.455744385465\n",
      "Model #363\tScore: -54520.08583593661\n",
      "Model #364\tScore: -56788.32610291049\n",
      "Model #365\tScore: -56458.29232040081\n",
      "Model #366\tScore: -56531.74420710079\n",
      "Model #367\tScore: -55924.70363460711\n",
      "Model #368\tScore: -63594.17442294914\n",
      "Model #369\tScore: -56964.188458328004\n",
      "Model #370\tScore: -54125.22970263374\n",
      "Model #371\tScore: -63351.578415758224\n",
      "Model #372\tScore: -55039.20840123912\n",
      "Model #373\tScore: -55094.22387324011\n",
      "Model #374\tScore: -59388.47262338238\n",
      "Model #375\tScore: -54689.054248037035\n",
      "Model #376\tScore: -56751.523922703585\n",
      "Model #377\tScore: -56713.932881669876\n",
      "Model #378\tScore: -57833.225612613685\n",
      "Model #379\tScore: -57665.96192971145\n",
      "Model #380\tScore: -57304.03406561716\n",
      "Model #381\tScore: -55197.301563366476\n",
      "Model #382\tScore: -53922.1667677156\n",
      "Model #383\tScore: -56320.33510161865\n",
      "Model #384\tScore: -54590.15340268504\n",
      "Model #385\tScore: -55469.953048314885\n",
      "Model #386\tScore: -55969.95502478093\n",
      "Model #387\tScore: -55005.23060660185\n",
      "Model #388\tScore: -57799.351414405355\n",
      "Model #389\tScore: -57503.42502826767\n",
      "Model #390\tScore: -60735.53129337847\n",
      "Model #391\tScore: -53801.38150431066\n",
      "Model #392\tScore: -56104.71734466719\n",
      "Model #393\tScore: -54721.46994131596\n",
      "Model #394\tScore: -55405.088777987534\n",
      "Model #395\tScore: -57776.403111504\n",
      "Model #396\tScore: -59751.45257419853\n",
      "Model #397\tScore: -56566.53968987217\n",
      "Model #398\tScore: -59553.70945120545\n",
      "Model #399\tScore: -56313.75783053771\n",
      "Model #400\tScore: -56976.771189923704\n",
      "Model #401\tScore: -56391.52813610614\n",
      "Model #402\tScore: -56188.29280863372\n",
      "Model #403\tScore: -56644.450464514084\n",
      "Model #404\tScore: -60727.73857848783\n",
      "Model #405\tScore: -58192.19654899112\n",
      "Model #406\tScore: -62304.5928560231\n",
      "Model #407\tScore: -54737.84865071943\n",
      "Model #408\tScore: -56302.41088940487\n",
      "Model #409\tScore: -54261.7076118077\n",
      "Model #410\tScore: -56575.76213044196\n",
      "Model #411\tScore: -55764.11402613689\n",
      "Model #412\tScore: -56812.97569613731\n",
      "Model #413\tScore: -56435.22321753499\n",
      "Model #414\tScore: -57523.64849855433\n",
      "Model #415\tScore: -54078.68339750785\n",
      "Model #416\tScore: -55074.85459282669\n",
      "Model #417\tScore: -55024.51840888443\n",
      "Model #418\tScore: -56164.39678365898\n",
      "Model #419\tScore: -56241.787994514605\n",
      "Model #420\tScore: -56727.860482715114\n",
      "Model #421\tScore: -62291.49923086277\n",
      "Model #422\tScore: -54539.98571538583\n",
      "Model #423\tScore: -57099.697377384786\n",
      "Model #424\tScore: -58628.82988693816\n",
      "Model #425\tScore: -55371.13688234198\n",
      "Model #426\tScore: -58422.38215057667\n",
      "Model #427\tScore: -56677.33469934604\n",
      "Model #428\tScore: -54924.871136989896\n",
      "Model #429\tScore: -56162.186214428206\n",
      "Model #430\tScore: -57373.44991613461\n",
      "Model #431\tScore: -55981.483062043444\n",
      "Model #432\tScore: -56333.832688795774\n",
      "Model #433\tScore: -57164.58510296794\n",
      "Model #434\tScore: -56595.1043163084\n",
      "Model #435\tScore: -56625.93327955959\n",
      "Model #436\tScore: -56896.559129316025\n",
      "Model #437\tScore: -55669.20560862589\n",
      "Model #438\tScore: -56583.378298907504\n",
      "Model #439\tScore: -54448.88678552008\n",
      "Model #440\tScore: -53987.59678909278\n",
      "Model #441\tScore: -57931.98969474347\n",
      "Model #442\tScore: -56628.369154463704\n",
      "Model #443\tScore: -59694.65749737141\n",
      "Model #444\tScore: -56167.69891168538\n",
      "Model #445\tScore: -59091.40759128773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #446\tScore: -56681.83152156538\n",
      "Model #447\tScore: -54082.60632905637\n",
      "Model #448\tScore: -56574.76849691731\n",
      "Model #449\tScore: -57798.38137138294\n",
      "Model #450\tScore: -60107.27474099731\n",
      "Model #451\tScore: -54254.71706230561\n",
      "Model #452\tScore: -56149.00814102015\n",
      "Model #453\tScore: -55572.487680084196\n",
      "Model #454\tScore: -57015.67257909641\n",
      "Model #455\tScore: -55740.46902000951\n",
      "Model #456\tScore: -59941.61650120631\n",
      "Model #457\tScore: -54739.77084602406\n",
      "Model #458\tScore: -55428.13366007939\n",
      "Model #459\tScore: -56098.04347335967\n",
      "Model #460\tScore: -55101.36157062467\n",
      "Model #461\tScore: -56248.76203355508\n",
      "Model #462\tScore: -56355.20772677359\n",
      "Model #463\tScore: -55258.50910582265\n",
      "Model #464\tScore: -56450.42412065242\n",
      "Model #465\tScore: -64527.81898269888\n",
      "Model #466\tScore: -56346.68487156028\n",
      "Model #467\tScore: -56311.60111765865\n",
      "Model #468\tScore: -60089.18563214491\n",
      "Model #469\tScore: -55152.16857104835\n",
      "Model #470\tScore: -57903.864588151\n",
      "Model #471\tScore: -60163.07100825318\n",
      "Model #472\tScore: -57256.83476601004\n",
      "Model #473\tScore: -54503.854180357164\n",
      "Model #474\tScore: -56124.99913145087\n",
      "Model #475\tScore: -59287.36567168535\n",
      "Model #476\tScore: -58241.0161619393\n",
      "Model #477\tScore: -55542.589029453724\n",
      "Model #478\tScore: -56614.76909882756\n",
      "Model #479\tScore: -55925.22533623035\n",
      "Model #480\tScore: -56594.05885921529\n",
      "Model #481\tScore: -55191.45404217801\n",
      "Model #482\tScore: -56711.64017647648\n",
      "Model #483\tScore: -56462.75850179037\n",
      "Model #484\tScore: -57299.45790003613\n",
      "Model #485\tScore: -56439.32305521855\n",
      "Model #486\tScore: -56966.822419222124\n",
      "Model #487\tScore: -56102.904011409766\n",
      "Model #488\tScore: -56616.531873746164\n",
      "Model #489\tScore: -56301.26900420584\n",
      "Model #490\tScore: -56784.33310102134\n",
      "Model #491\tScore: -55517.20928349883\n",
      "Model #492\tScore: -56761.207894412575\n",
      "Model #493\tScore: -57348.53367267338\n",
      "Model #494\tScore: -56474.068391702844\n",
      "Model #495\tScore: -57583.570547435236\n",
      "Model #496\tScore: -56810.17611086632\n",
      "Model #497\tScore: -59154.40938013516\n",
      "Model #498\tScore: -62169.14074488772\n",
      "Model #499\tScore: -56357.827994452266\n",
      "Model #500\tScore: -56779.209465635664\n",
      "Model #501\tScore: -56102.74944871503\n",
      "Model #502\tScore: -54236.24570340977\n",
      "Model #503\tScore: -56191.54865018095\n",
      "Model #504\tScore: -58368.96975568103\n",
      "Model #505\tScore: -56284.884634782444\n",
      "Model #506\tScore: -54652.075234706586\n",
      "Model #507\tScore: -56709.834838275754\n",
      "Model #508\tScore: -59112.03109028511\n",
      "Model #509\tScore: -59210.76555438479\n",
      "Model #510\tScore: -55630.58372181756\n",
      "Model #511\tScore: -56230.193923394996\n",
      "Model #512\tScore: -55552.393174754754\n",
      "Model #513\tScore: -53782.68646163264\n",
      "Model #514\tScore: -56343.62729459703\n",
      "Model #515\tScore: -56374.119922214464\n",
      "Model #516\tScore: -55218.91981496511\n",
      "Model #517\tScore: -57683.67786842928\n",
      "Model #518\tScore: -58442.57664314898\n",
      "Model #519\tScore: -55786.25699213697\n",
      "Model #520\tScore: -57897.67910191564\n",
      "Model #521\tScore: -56113.78291433842\n",
      "Model #522\tScore: -64267.303981798956\n",
      "Model #523\tScore: -61359.85133581493\n",
      "Model #524\tScore: -57149.94043907319\n",
      "Model #525\tScore: -58211.69798067328\n",
      "Model #526\tScore: -59863.757271884206\n",
      "Model #527\tScore: -58309.99299274891\n",
      "Model #528\tScore: -56625.43404378727\n",
      "Model #529\tScore: -64815.36075007552\n",
      "Model #530\tScore: -56125.26292904179\n",
      "Model #531\tScore: -58573.807401000064\n",
      "Model #532\tScore: -57022.24104143593\n",
      "Model #533\tScore: -56625.637794048554\n",
      "Model #534\tScore: -59161.14237990384\n",
      "Model #535\tScore: -56469.8164673112\n",
      "Model #536\tScore: -54874.159142663775\n",
      "Model #537\tScore: -63644.602635017\n",
      "Model #538\tScore: -56220.41482635162\n",
      "Model #539\tScore: -54425.41026268056\n",
      "Model #540\tScore: -58173.52838599365\n",
      "Model #541\tScore: -56386.216141266494\n",
      "Model #542\tScore: -56706.13852555397\n",
      "Model #543\tScore: -54829.8928383604\n",
      "Model #544\tScore: -56604.66448544159\n",
      "Model #545\tScore: -60413.563343919945\n",
      "Model #546\tScore: -56557.86122128088\n",
      "Model #547\tScore: -56583.9177054378\n",
      "Model #548\tScore: -56784.14882831824\n",
      "Model #549\tScore: -55511.184662527296\n",
      "Model #550\tScore: -54699.842715109604\n",
      "Model #551\tScore: -56721.1263131954\n",
      "Model #552\tScore: -58803.16832241791\n",
      "Model #553\tScore: -59945.69807569702\n",
      "Model #554\tScore: -58126.906763912\n",
      "Model #555\tScore: -62454.43521393509\n",
      "Model #556\tScore: -56107.109730796365\n",
      "Model #557\tScore: -56494.29031573967\n",
      "Model #558\tScore: -56786.67366821552\n",
      "Model #559\tScore: -56228.748529287004\n",
      "Model #560\tScore: -56817.80157837606\n",
      "Model #561\tScore: -57191.89055276657\n",
      "Model #562\tScore: -56089.55498773385\n",
      "Model #563\tScore: -59693.57840350162\n",
      "Model #564\tScore: -57444.588363989045\n",
      "Model #565\tScore: -56783.03806464688\n",
      "Model #566\tScore: -57327.822736225615\n",
      "Model #567\tScore: -55199.571251066605\n",
      "Model #568\tScore: -57603.18351043828\n",
      "Model #569\tScore: -58881.70355682286\n",
      "Model #570\tScore: -60241.578905589384\n",
      "Model #571\tScore: -56328.337142473676\n",
      "Model #572\tScore: -54963.888325296095\n",
      "Model #573\tScore: -55622.00096244556\n",
      "Model #574\tScore: -55728.81195868807\n",
      "Model #575\tScore: -56124.11283731103\n",
      "Model #576\tScore: -56479.51116214917\n",
      "Model #577\tScore: -56007.15836066089\n",
      "Model #578\tScore: -56167.5115832624\n",
      "Model #579\tScore: -55938.99109821589\n",
      "Model #580\tScore: -56291.98313107378\n",
      "Model #581\tScore: -58597.81727708808\n",
      "Model #582\tScore: -55983.4421615351\n",
      "Model #583\tScore: -55065.33758850029\n",
      "Model #584\tScore: -56490.56015047036\n",
      "Model #585\tScore: -56031.70037295625\n",
      "Model #586\tScore: -58459.68072912847\n",
      "Model #587\tScore: -56163.63478878912\n",
      "Model #588\tScore: -55006.806122171445\n",
      "Model #589\tScore: -56233.85030519163\n",
      "Model #590\tScore: -56129.13746398225\n",
      "Model #591\tScore: -56488.02835120255\n",
      "Model #592\tScore: -56224.70521859359\n",
      "Model #593\tScore: -56778.3723271615\n",
      "Model #594\tScore: -65457.55707804606\n",
      "Model #595\tScore: -58310.022834762865\n",
      "Model #596\tScore: -59665.68873277495\n",
      "Model #597\tScore: -59866.48953285957\n",
      "Model #598\tScore: -56124.91077424784\n",
      "Model #599\tScore: -56438.764816711366\n",
      "Model #600\tScore: -55949.28392092649\n",
      "Model #601\tScore: -56660.125070623246\n",
      "Model #602\tScore: -56539.446158451006\n",
      "Model #603\tScore: -55115.01498493979\n",
      "Model #604\tScore: -54984.990174469145\n",
      "Model #605\tScore: -53921.02188057564\n",
      "Model #606\tScore: -59526.07697329666\n",
      "Model #607\tScore: -56626.69983255296\n",
      "Model #608\tScore: -60823.586812889334\n",
      "Model #609\tScore: -55686.22235996943\n",
      "Model #610\tScore: -56084.18306932366\n",
      "Model #611\tScore: -56270.61593752783\n",
      "Model #612\tScore: -57550.11023782332\n",
      "Model #613\tScore: -59098.680692118025\n",
      "Model #614\tScore: -63917.02649642274\n",
      "Model #615\tScore: -57982.56970792133\n",
      "Model #616\tScore: -56287.769704698425\n",
      "Model #617\tScore: -62227.3313049757\n",
      "Model #618\tScore: -56188.81479943554\n",
      "Model #619\tScore: -55229.43041488953\n",
      "Model #620\tScore: -56744.285806598054\n",
      "Model #621\tScore: -57119.002113021364\n",
      "Model #622\tScore: -55383.57539843415\n",
      "Model #623\tScore: -56127.33377792393\n",
      "Model #624\tScore: -64855.74621676933\n",
      "Model #625\tScore: -55958.62936177057\n",
      "Model #626\tScore: -56127.036936251185\n",
      "Model #627\tScore: -57778.19319204492\n",
      "Model #628\tScore: -56495.475112893866\n",
      "Model #629\tScore: -57422.86201978056\n",
      "Model #630\tScore: -56331.98207672221\n",
      "Model #631\tScore: -56470.6528221348\n",
      "Model #632\tScore: -63440.9785932695\n",
      "Model #633\tScore: -57693.44786890214\n",
      "Model #634\tScore: -55850.65229033191\n",
      "Model #635\tScore: -54239.51673315961\n",
      "Model #636\tScore: -55158.43497506306\n",
      "Model #637\tScore: -54962.202471630226\n",
      "Model #638\tScore: -56480.84633872423\n",
      "Model #639\tScore: -54965.75335382723\n",
      "Model #640\tScore: -56366.98727811989\n",
      "Model #641\tScore: -55305.792731046\n",
      "Model #642\tScore: -56167.06102331013\n",
      "Model #643\tScore: -56226.347161762984\n",
      "Model #644\tScore: -55443.06558046835\n",
      "Model #645\tScore: -59135.75386844049\n",
      "Model #646\tScore: -54400.689027758\n",
      "Model #647\tScore: -57828.18575150388\n",
      "Model #648\tScore: -56114.80207000641\n",
      "Model #649\tScore: -56175.358027713395\n",
      "Model #650\tScore: -56473.33369368673\n",
      "Model #651\tScore: -55279.87360811545\n",
      "Model #652\tScore: -56227.007242632884\n",
      "Model #653\tScore: -56620.52875651269\n",
      "Model #654\tScore: -53831.58905321997\n",
      "Model #655\tScore: -56668.9555880047\n",
      "Model #656\tScore: -59727.09897662461\n",
      "Model #657\tScore: -56275.87651592811\n",
      "Model #658\tScore: -57215.577665878256\n",
      "Model #659\tScore: -56681.78742592572\n",
      "Model #660\tScore: -55961.50683483327\n",
      "Model #661\tScore: -55107.05453489285\n",
      "Model #662\tScore: -54849.98849226053\n",
      "Model #663\tScore: -55187.22264357089\n",
      "Model #664\tScore: -58757.32238482615\n",
      "Model #665\tScore: -54279.0851265612\n",
      "Model #666\tScore: -56481.67730361902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #667\tScore: -55856.89482960426\n",
      "Model #668\tScore: -56775.15344882214\n",
      "Model #669\tScore: -61774.69173873404\n",
      "Model #670\tScore: -56158.46899985927\n",
      "Model #671\tScore: -56190.91839713352\n",
      "Model #672\tScore: -56703.73106771803\n",
      "Model #673\tScore: -56234.64725030709\n",
      "Model #674\tScore: -56421.91865983214\n",
      "Model #675\tScore: -55060.44332013072\n",
      "Model #676\tScore: -58543.38093037439\n",
      "Model #677\tScore: -56260.05627542844\n",
      "Model #678\tScore: -54132.50827505414\n",
      "Model #679\tScore: -57423.40400082283\n",
      "Model #680\tScore: -55088.93228762128\n",
      "Model #681\tScore: -56092.330219411066\n",
      "Model #682\tScore: -59010.90839335933\n",
      "Model #683\tScore: -56101.526195446204\n",
      "Model #684\tScore: -56129.68791632952\n",
      "Model #685\tScore: -54731.88877117955\n",
      "Model #686\tScore: -58268.03061424554\n",
      "Model #687\tScore: -59666.62434602788\n",
      "Model #688\tScore: -55975.84619832219\n",
      "Model #689\tScore: -56156.883332366924\n",
      "Model #690\tScore: -54774.18938883415\n",
      "Model #691\tScore: -56614.126005533486\n",
      "Model #692\tScore: -56206.48439465264\n",
      "Model #693\tScore: -54887.111773654404\n",
      "Model #694\tScore: -56285.04026861516\n",
      "Model #695\tScore: -58257.236915252535\n",
      "Model #696\tScore: -54078.94610691709\n",
      "Model #697\tScore: -58468.45424190064\n",
      "Model #698\tScore: -56155.533362095404\n",
      "Model #699\tScore: -55195.044142444414\n",
      "Model #700\tScore: -56292.878746158676\n",
      "Model #701\tScore: -56118.68545687851\n",
      "Model #702\tScore: -56341.51181126894\n",
      "Model #703\tScore: -54698.484346313686\n",
      "Model #704\tScore: -56783.101366643736\n",
      "Model #705\tScore: -56918.7634388454\n",
      "Model #706\tScore: -56753.97284454241\n",
      "Model #707\tScore: -56538.88962527716\n",
      "Model #708\tScore: -59368.8449345866\n",
      "Model #709\tScore: -56423.35363370827\n",
      "Model #710\tScore: -63783.20307517597\n",
      "Model #711\tScore: -54601.28843720324\n",
      "Model #712\tScore: -56480.70407870436\n",
      "Model #713\tScore: -57959.54477529858\n",
      "Model #714\tScore: -56671.764136154765\n",
      "Model #715\tScore: -55672.11038834825\n",
      "Model #716\tScore: -56459.42425470959\n",
      "Model #717\tScore: -60734.816974310714\n",
      "Model #718\tScore: -59552.41270878423\n",
      "Model #719\tScore: -56199.064412989974\n",
      "Model #720\tScore: -60518.33914189135\n",
      "Model #721\tScore: -57593.72085600623\n",
      "Model #722\tScore: -57168.83348607969\n",
      "Model #723\tScore: -56847.93237463099\n",
      "Model #724\tScore: -56784.62354508658\n",
      "Model #725\tScore: -55888.83647639868\n",
      "Model #726\tScore: -55403.84193647943\n",
      "Model #727\tScore: -56113.19268755116\n",
      "Model #728\tScore: -55984.68836564976\n",
      "Model #729\tScore: -56439.81152117637\n",
      "Model #730\tScore: -55701.311078078135\n",
      "Model #731\tScore: -56366.32884519207\n",
      "Model #732\tScore: -61745.02699112461\n",
      "Model #733\tScore: -58642.984921578056\n",
      "Model #734\tScore: -56565.75513580301\n",
      "Model #735\tScore: -56462.7784708719\n",
      "Model #736\tScore: -55593.82460178269\n",
      "Model #737\tScore: -56102.374308162856\n",
      "Model #738\tScore: -54493.74888496925\n",
      "Model #739\tScore: -62464.64872609005\n",
      "Model #740\tScore: -59390.22200324702\n",
      "Model #741\tScore: -56146.32285329331\n",
      "Model #742\tScore: -56620.32349888556\n",
      "Model #743\tScore: -56692.7370822818\n",
      "Model #744\tScore: -55648.28474582587\n",
      "Model #745\tScore: -55537.385563224634\n",
      "Model #746\tScore: -60150.284930087444\n",
      "Model #747\tScore: -64078.01405212641\n",
      "Model #748\tScore: -56368.6854232702\n",
      "Model #749\tScore: -53944.710928816006\n",
      "Model #750\tScore: -55389.79097781989\n",
      "Model #751\tScore: -56107.273945325534\n",
      "Model #752\tScore: -55240.09991380628\n",
      "Model #753\tScore: -56499.01289837004\n",
      "Model #754\tScore: -56575.71581598925\n",
      "Model #755\tScore: -58312.10333113735\n",
      "Model #756\tScore: -56190.790655769335\n",
      "Model #757\tScore: -55143.823401000074\n",
      "Model #758\tScore: -56515.67811373291\n",
      "Model #759\tScore: -56590.687581182545\n",
      "Model #760\tScore: -56551.46211675864\n",
      "Model #761\tScore: -56710.90577792595\n",
      "Model #762\tScore: -56488.42049251435\n",
      "Model #763\tScore: -56762.92916448597\n",
      "Model #764\tScore: -56682.58506767457\n",
      "Model #765\tScore: -56960.11934034046\n",
      "Model #766\tScore: -55963.72265105066\n",
      "Model #767\tScore: -54950.987408642366\n",
      "Model #768\tScore: -56269.72569952998\n",
      "Model #769\tScore: -58608.092062149364\n",
      "Model #770\tScore: -56115.87531539854\n",
      "Model #771\tScore: -56504.39011505188\n",
      "Model #772\tScore: -59339.10029769903\n",
      "Model #773\tScore: -57598.29117070233\n",
      "Model #774\tScore: -56117.638313935735\n",
      "Model #775\tScore: -56399.48538912893\n",
      "Model #776\tScore: -56517.70006656659\n",
      "Model #777\tScore: -56129.22991119252\n",
      "Model #778\tScore: -56652.78242678806\n",
      "Model #779\tScore: -59440.493674854464\n",
      "Model #780\tScore: -56632.131729902685\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23748/2624897473.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_fits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodeleach\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalHMM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmodeleach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml_seq\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mn_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodeleach\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Model #{i+1}\\tScore: {score}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hmmlearn\\hmm.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m         wrapper = functools.wraps(func)(\n\u001b[1;32m--> 517\u001b[1;33m             lambda *args, **kwargs: func(*args, **kwargs))\n\u001b[0m\u001b[0;32m    518\u001b[0m         wrapper.__doc__ = (\n\u001b[0;32m    519\u001b[0m             \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"(n_samples, n_features)\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"(n_samples, 1)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hmmlearn\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, lengths)\u001b[0m\n\u001b[0;32m    513\u001b[0m                 \u001b[1;31m# update their probability distributions, so keep\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;31m# a single call to this method for simplicity.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m                 self._accumulate_sufficient_statistics(\n\u001b[0m\u001b[0;32m    516\u001b[0m                     \u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlattice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposteriors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfwdlattice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m                     bwdlattice)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\hmmlearn\\hmm.py\u001b[0m in \u001b[0;36m_accumulate_sufficient_statistics\u001b[1;34m(self, stats, X, lattice, posteriors, fwdlattice, bwdlattice)\u001b[0m\n\u001b[0;32m    671\u001b[0m             stats, X, lattice, posteriors, fwdlattice, bwdlattice)\n\u001b[0;32m    672\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'e'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'obs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposteriors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_do_mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#í•™ìŠµì„ ë°˜ë³µí•´ì„œ ë°°ìŠ¤íŠ¸ ëª¨ë¸ì„ ì°¾ê¸°\n",
    "# repeating and finding the best results (random initialization)\n",
    "\n",
    "best_score = best_model = None\n",
    "n_fits = 2000\n",
    "for i in range(n_fits):\n",
    "    modeleach = hmm.CategoricalHMM(n_components=2)\n",
    "    modeleach.fit(Xseq,[l_seq]*n_sample)\n",
    "    score = modeleach.score(Xseq)\n",
    "    print(f'Model #{i+1}\\tScore: {score}')\n",
    "    if best_score is None or score > best_score:\n",
    "        best_model = modeleach\n",
    "        best_score = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5518a742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-53685.79894358745"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "fc9d52f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.995, 0.005])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.startprob_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b91a9109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.637, 0.363],\n",
       "       [0.167, 0.833]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.transmat_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1a2398cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.546, 0.454],\n",
       "       [0.01 , 0.99 ]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.emissionprob_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d682e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
